import SwiftUI
import ShazamKit
import AVFoundation

// ê³¡ ì¸ì‹ ê´€ë¦¬ í´ëž˜ìŠ¤
class ShazamRecognizer: NSObject, ObservableObject {
    private let audioEngine = AVAudioEngine()
    private let session = SHSession()
    private let matchDelegate = MatchDelegate()
    
    @Published var matchedSong: SHMatchedMediaItem?
    @Published var didNotFindSong: Bool = false // â— ì‹¤íŒ¨ ì—¬ë¶€ ìƒíƒœ ì¶”ê°€
    
    override init() {
        super.init()
        session.delegate = matchDelegate
        // ë…¸ëž˜ ë§¤ì¹­ì‹œ ê²°ê³¼ì²˜ë¦¬
        matchDelegate.onMatch = {
            [weak self] mediaItem in DispatchQueue.main.async {
                self?.matchedSong = mediaItem
                self?.stopListening() // ë§¤ì¹­ì™„ë£Œì‹œ ìžë™ì¢…ë£Œ
            }
        }
        // ë§Œì•½ ë§¤ì¹­ë˜ëŠ” ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° ì²˜ë¦¬ë°©ë²•
        matchDelegate.onNoMatch = { [weak self] in
            DispatchQueue.main.async {
                self?.matchedSong = nil
                self?.didNotFindSong = true // â— ì‹¤íŒ¨ ìƒíƒœ í‘œì‹œ
                self?.stopListening()
            }
        }
    }
    
    // ë…¸ëž˜ ë“¤ì„ ë•Œ í•¨ìˆ˜
    func startListening() throws {
#if targetEnvironment(simulator)
        print("âš ï¸ ì‹œë®¬ë ˆì´í„°ì—ì„œëŠ” ë§ˆì´í¬ ì¸ì‹ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
        return
#else
        guard !isListening else { return }
        
        let inputNode = audioEngine.inputNode
        let format = inputNode.outputFormat(forBus: 0)
        
        session.delegate = matchDelegate
        
        inputNode.removeTap(onBus: 0) // í˜¹ì‹œ ì´ì „ tapì´ ë‚¨ì•„ìžˆì„ ê²½ìš° ëŒ€ë¹„
        
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: format) { buffer, time in
            self.session.matchStreamingBuffer(buffer, at: time)
        }
        
        audioEngine.prepare()
        try audioEngine.start()
#endif
    }
    // ë…¸ëž˜ ë“£ê¸° ë§ˆì¹˜ëŠ” í•¨ìˆ˜
    func stopListening() {
        audioEngine.stop()
        audioEngine.inputNode.removeTap(onBus: 0)
    }
}

// SHSession ê²°ê³¼ì²˜ë¦¬ ë¸ë¦¬ê²Œì´íŠ¸
class MatchDelegate: NSObject, SHSessionDelegate {
    var onMatch: ((SHMatchedMediaItem) -> Void)?
    var onNoMatch: (() -> Void)? // â— ì‹¤íŒ¨ ì½œë°± ì¶”ê°€
    
    func session(_ session: SHSession, didFind match: SHMatch) {
        guard let mediaItem = match.mediaItems.first else { return }
        onMatch?(mediaItem)
    }
    func session(_ session: SHSession, didNotFindMatchFor signature: SHSignature) {
        // â— ê³¡ì„ ì°¾ì§€ ëª»í–ˆì„ ë•Œ ì‹¤í–‰ë¨
        onNoMatch?()
    }
}

// ìŒì•…ì¸ì‹ ê²€ìƒ‰ ë·°
struct SongSearchView: View {
    @Environment(\.presentationMode) var presentationMode
    @StateObject private var recognizer = ShazamRecognizer()
    @State private var permissionMessage = ""
    @State private var isShowPermissionAlert = false
    @State private var isShowRecognizerAlert = false
    
    @State private var promptText = "ë…¸ëž˜ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”"
    
    @State private var isResultViewActive: Bool = false
    
//    @ObservedObject private var recognizer = ShazamRecognizer()
    let onSearchCompleted: (SHMatchedMediaItem?) -> Void // ðŸ” ê²°ê³¼ë¥¼ ë„˜ê¸¸ ì½œë°±
    
    var body: some View {
        VStack() {
            HStack {
                if let item = recognizer.matchedSong {
                    Text("Title: \(item.title ?? "Unknown")")
                    Text("Artist: \(item.artist ?? "Unknown")")
                } else if recognizer.didNotFindSong {
                    Text("ì°¾ìœ¼ì‹œëŠ” ë…¸ëž˜ê°€ ì—†ì–´ìš”")
                }
                else {
                    Text("ë“£ê³  ìžˆì–´ìš”...")
                }
                Button(action: {
                    Task {
                        let permissionStatus = await requestMicPermission()
                        if permissionStatus == .granted {
                            startSongRecognition()
                        } else {
                            // ê¶Œí•œ ë¹„í—ˆìš©ì‹œ ì‚¬ìš©ìžì—ê²Œ ì•ˆë‚´í•˜ê¸°
                            permissionMessage = "ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤."
                            isShowPermissionAlert = true
                        }
                    }
                    presentationMode.wrappedValue.dismiss()
                    try? recognizer.startListening()
                }) {
                    // [ì´ì „(ëŒì•„ê°€ê¸°) ë²„íŠ¼]
                    ZStack {
                        Rectangle()
                            .foregroundColor(.clear)
                            .frame(width: 150, height: 110)
                            .background(Color(red: 0.34, green: 0.34, blue: 0.34))
                            .cornerRadius(20)
                        Image("Ellipse 11")
                            .frame(width: 120, height: 82)
                            .background(Color(red: 0.22, green: 0.22, blue: 0.22))
                        Text("ì´ì „")
                            .font(
                                Font.custom("SF Pro", size: 48)
                                    .weight(.medium)
                            )
                            .foregroundColor(Color(red: 0.92, green: 0.91, blue: 0.87))
                    }
                }
                .padding()
                Spacer()
            }
            Spacer()
            
            // [waveform ì• ë‹ˆë©”ì´ì…˜ ì´ë¯¸ì§€ ì‚½ìž…]
            ZStack{
                Rectangle()
                    .foregroundColor(.clear)
                    .frame(width: 260, height: 260)
                    .background(Color(red: 0.22, green: 0.22, blue: 0.22))
                    .cornerRadius(260)
                    .shadow(color: .black.opacity(0.25), radius: 10, x: 0, y: 0)
                Rectangle()
                    .foregroundColor(.clear)
                    .frame(width: 238, height: 238)
                    .background(Color(red: 0.92, green: 0.9, blue: 0.88))
                    .cornerRadius(260)
                    .shadow(color: .black.opacity(0.25), radius: 10, x: 0, y: 0)
                Image(systemName: "waveform")
                    .resizable()
                    .frame(width: 238, height: 238)
                    .symbolEffect(.breathe)
            }
            Spacer()
            
            Text(promptText)
                .font(
                    Font.custom("SF Pro", size: 64)
                        .weight(.medium)
                )
                .multilineTextAlignment(.center)
                .foregroundColor(Color(red: 0.22, green: 0.22, blue: 0.22))
                .transition(.opacity)
                .animation(.easeInOut(duration: 0.5), value: promptText)
            Spacer()
        }
        .navigationBarBackButtonHidden(true) // ê¸°ë³¸ ë’¤ë¡œê°€ê¸° ë²„íŠ¼ ìˆ¨ê¹€
        
        .onAppear {
            try? recognizer.startListening()
            DispatchQueue.main.asyncAfter(deadline: .now() + 1.5) {
                withAnimation {
                    promptText = "ì§€ê¸ˆ ë“¤ë ¤ì£¼ì„¸ìš”. ë“£ê³  ìžˆì–´ìš”"
                }
            }
        }
        .onChange(of: recognizer.matchedSong) { newValue in
            if newValue != nil {
                onSearchCompleted(newValue)
            }
        }
        .onChange(of: recognizer.didNotFindSong) { didFail in
            if didFail {
                onSearchCompleted(nil)
            }
        }
    }
}

extension SongSearchView{
    
    private func requestMicPermission() async -> MicPermissionStatus {
        let permission = AVAudioApplication.shared.recordPermission
        switch permission {
        case .granted:
            return .granted
        case .denied:
            return .denied
        case .undetermined:
            return await withCheckedContinuation { continuation in
                AVAudioApplication.requestRecordPermission { granted in
                    continuation.resume(returning: granted ? .granted : .denied)
                }
            }
        @unknown default:
            return .undetermined
        }
    }
    
    private func startSongRecognition() {
        try? recognizer.startListening()
    }
    
    private func stopSongRecognition() {
        recognizer.stopListening()
    }
}
