import SwiftUI
import ShazamKit
import AVFoundation
import MusicKit

/*
// ê²€ìƒ‰ê²°ê³¼ íŽ˜ì´ì§€ì— ë„˜ê²¨ì£¼ëŠ” ë°ì´í„°ëª¨ë¸(ìƒ¤ìž í‚· > ë®¤ì§í‚·)
struct Item: Identifiable, Equatable, Hashable {
    let id: String
    let title: String
    let artist: String
    let previewURL: URL?
    let artworkURL: URL?
    
    init(
        id: String,
        title: String,
        artist: String,
        previewURL: URL? = nil,
        artworkURL: URL? = nil)
    {
        self.id = id
        self.title = title
        self.artist = artist
        self.previewURL = previewURL
        self.artworkURL = artworkURL
    }
}
 */

// ê³¡ ì •ë³´ ë°ì´í„°ëª¨ë¸
struct ShazamSongInformation: Hashable {
    let s_title: String
    let s_artist: String
    let s_artworkURL: URL?
    let s_previewURL: URL?
}

// ê³¡ ì¸ì‹ ê´€ë¦¬ í´ëž˜ìŠ¤
class ShazamRecognizer: NSObject, ObservableObject {
    private let audioEngine = AVAudioEngine()
    private let session = SHSession()
    private let matchDelegate = MatchDelegate()
    
    @Published var matchedSong: SHMediaItem?
    @Published var didNotFindSong: Bool = false // ì‹¤íŒ¨ ì—¬ë¶€ ìƒíƒœ ì¶”ê°€
    
    override init() {
        super.init()
        session.delegate = matchDelegate
        
        // ë…¸ëž˜ ë§¤ì¹­ì‹œ ê²°ê³¼ì²˜ë¦¬
        matchDelegate.onMatch = {
            [weak self] mediaItem in DispatchQueue.main.async {
                self?.matchedSong = mediaItem
                self?.stopListening() // ë§¤ì¹­ì™„ë£Œì‹œ ìžë™ì¢…ë£Œ
            }
        }
        // ë§Œì•½ ë§¤ì¹­ë˜ëŠ” ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° ì²˜ë¦¬ë°©ë²•
        matchDelegate.onNoMatch = { [weak self] in
            DispatchQueue.main.async {
                self?.matchedSong = nil
                self?.didNotFindSong = true // ì‹¤íŒ¨ ìƒíƒœ í‘œì‹œ
                self?.stopListening()
            }
        }
    }
    
    // ë…¸ëž˜ ë“¤ì„ ë•Œ í•¨ìˆ˜
    func startListening() throws {
#if targetEnvironment(simulator)
        print("âš ï¸ ì‹œë®¬ë ˆì´í„°ì—ì„œëŠ” ë§ˆì´í¬ ì¸ì‹ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
        return
#else
        let inputNode = audioEngine.inputNode
        let format = inputNode.outputFormat(forBus: 0)
        
        session.delegate = matchDelegate
        
        inputNode.removeTap(onBus: 0) // í˜¹ì‹œ ì´ì „ tapì´ ë‚¨ì•„ìžˆì„ ê²½ìš° ëŒ€ë¹„
        
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: format) { buffer, time in
            self.session.matchStreamingBuffer(buffer, at: time)
        }
        
        audioEngine.prepare()
        try audioEngine.start()
#endif
    }
    // ë…¸ëž˜ ë“£ê¸° ë§ˆì¹˜ëŠ” í•¨ìˆ˜
    func stopListening() {
        audioEngine.stop()
        audioEngine.inputNode.removeTap(onBus: 0)
    }
}

// SHSession ê²°ê³¼ì²˜ë¦¬ ë¸ë¦¬ê²Œì´íŠ¸
class MatchDelegate: NSObject, SHSessionDelegate {
    var onMatch: ((SHMediaItem) -> Void)?
    var onNoMatch: (() -> Void)? // ì‹¤íŒ¨ ì½œë°± ì¶”ê°€
    
    func session(_ session: SHSession, didFind match: SHMatch) {
        guard let mediaItem = match.mediaItems.first else { return }
        onMatch?(mediaItem)
    }
    func session(_ session: SHSession, didNotFindMatchFor signature: SHSignature) {
        // â— ê³¡ì„ ì°¾ì§€ ëª»í–ˆì„ ë•Œ ì‹¤í–‰ë¨
        onNoMatch?()
    }
}

// ë„¤ë¹„ê²Œì´ì…˜ íƒ€ê²Ÿ
enum NavigationTarget: Hashable {
    case result(ShazamSongInformation?)
}

// ìŒì•…ì¸ì‹ ê²€ìƒ‰ ë·°
struct SongSearchView: View {
    @Environment(\.presentationMode) var presentationMode
    @StateObject private var recognizer = ShazamRecognizer()
    @State private var promptText = "ë…¸ëž˜ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”"
    @State private var permissionChecked = false
    @Binding var path: NavigationPath
    
    //    @State private var isShowPermissionAlert = false
    //    @State private var isShowRecognizerAlert = false
    //    @State private var isMatchFound = false
    
    // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
    private func requestMicPermission() async -> MicPermissionStatus {
        let permission = AVAudioApplication.shared.recordPermission
        switch permission {
        case .granted:
            return .granted
        case .denied:
            return .denied
        case .undetermined:
            return await withCheckedContinuation { continuation in
                AVAudioApplication.requestRecordPermission { granted in
                    continuation.resume(returning: granted ? .granted : .denied)
                }
            }
        @unknown default:
            return .undetermined
        }
    }
    
    // ë§ˆì´í¬ ì‚¬ìš©ê¶Œí•œ í™•ì¸ & ìƒ¤ìž  ìžë™ì‹¤í–‰
    private func startRecognitionFlow() async {
        let permission = await requestMicPermission()
        if permission == .granted {
            promptText = "ë…¸ëž˜ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”. ë“£ê³  ìžˆì–´ìš”"
            recognizer.didNotFindSong = false
            recognizer.matchedSong = nil
            try? recognizer.startListening()
        } else {
            promptText = "âš ï¸ ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤"
        }
    }
    
    // ê²€ìƒ‰ ìž¬ì‹œìž‘ ì „ ì´ˆê¸°í™” í¬í•¨
    private func restartListening() async {
        recognizer.stopListening()
        await startRecognitionFlow()
    }
    
    var body: some View {
        VStack {
            HStack {
                Button("ì´ì „") {
                    path = NavigationPath() // ë©”ì¸ ë·°ë¡œ ë³µê·€
                }
                Spacer()
                
                Button("ê²€ìƒ‰") {
                    Task {
                        await startRecognitionFlow()
                    }
                }
            }
            Spacer()
            
            // ðŸ’› To-do : [ë¡œë  ì• ë‹ˆë©”ì´ì…˜ìœ¼ë¡œ ëŒ€ì²´ë  ë¶€ë¶„]
            Image(systemName: "waveform")
                .resizable()
                .frame(width: 200, height: 200)
                .symbolEffect(.breathe)
            
            Spacer()
            
            Text(promptText)
                .font(.title)
                .multilineTextAlignment(.center)
                .foregroundColor(Color(red: 0.22, green: 0.22, blue: 0.22))
                .transition(.opacity)
                .animation(.easeInOut(duration: 0.5), value: promptText)
        }
        // í™”ë©´ ì§„ìž…ì‹œ ë§ˆì´í¬ ì‚¬ìš©ê¶Œí•œ í™•ì¸ & ìƒ¤ìž  ìžë™ì‹¤í–‰
        .onAppear {
            Task {
                if !permissionChecked {
                    permissionChecked = true
                    await startRecognitionFlow()
                } else {
                    await restartListening() // ë‹¤ì‹œ ëŒì•„ì™”ì„ ë•Œë„ ìžë™ ì‹œìž‘
                }
            }
        }
        // ê³¡ ê²€ìƒ‰ì— ì„±ê³µì‹œ matchedSongì„ ê°ì§€í•˜ì—¬ ìƒíƒœë³€ê²½
        .onReceive(recognizer.$matchedSong) { item in
            if let item = item {
                let info = ShazamSongInformation(
                    s_title: item.title ?? "ì œëª© ì—†ìŒ",
                    s_artist: item.artist ?? "ì•„í‹°ìŠ¤íŠ¸ ì—†ìŒ",
                    s_artworkURL: item.artworkURL,
                    s_previewURL: item.appleMusicURL
                )
                path.append(NavigationTarget.result(info))
            }
        }
        // ë§¤ì¹˜í•˜ëŠ” ê³¡ ê²€ìƒ‰ì— ì‹¤íŒ¨ì‹œ
        .onReceive(recognizer.$didNotFindSong) { notFound in
            if notFound {
                path.append(NavigationTarget.result(nil))
            }
        }
        Spacer()
    }
}

// ìƒ¤ìž í‚·ì—ì„œ ë®¤ì§í‚·(ì• í”Œ ë®¤ì§ ë¼ì´ë¸ŒëŸ¬ë¦¬) ë°ì´í„°ë¥¼ ë°›ì•„ì˜¤ëŠ” í•¨ìˆ˜
//func getAppleMusicData() -> [String] {
//    
//}
